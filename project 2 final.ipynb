{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b66801",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 2 - Ames Housing Data and Kaggle Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d1ca1",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e25058",
   "metadata": {},
   "source": [
    "There are are many variables that determine how much a home can fetch.\n",
    "Using the Ames (IA) dataset (train, test), we want to find out which variables matter for home sale prices and produce accurate sale price predictions. \n",
    "This model will help provide the Outside View*, helping to reduce information asymmetry between potential home-buyers, home-sellers and real estate agents, and the success of the model will depend on the accuracy on how well the model is able to predict home prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff32b53",
   "metadata": {},
   "source": [
    "### Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf697ba3",
   "metadata": {},
   "source": [
    "* Background\n",
    "* Data sets used\n",
    "* Data Import\n",
    "* Cleaning Train Dataset\n",
    "* Exploratory Data Analysis\n",
    "* Train and Test Model\n",
    "* Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0ecde",
   "metadata": {},
   "source": [
    "### Background "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8b7a2",
   "metadata": {},
   "source": [
    "The original original intent for the data was to be used for tax assessment purposes but lends itself directly to the prediction of home selling prices. The type of information contained in the data is similar to what a typical home buyer would want to know before making a purchase, like size, neighborhood, exterior, basement, sale price, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fce97",
   "metadata": {},
   "source": [
    "### Data sets used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f83e3",
   "metadata": {},
   "source": [
    "* train.csv\n",
    "* test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468e148",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbdcb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,  GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, mean_absolute_error, mean_squared_error\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./datasets/train.csv')\n",
    "test_df = pd.read_csv('./datasets/test.csv')\n",
    "\n",
    "# backup df\n",
    "old_train_df = train_df\n",
    "old_test_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ab344",
   "metadata": {},
   "source": [
    "### Cleaning Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8806b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c949d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b2fb2",
   "metadata": {},
   "source": [
    "###### Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65163fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19323a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit column names -> lower case -> replace space with _\n",
    "\n",
    "train_df.columns= train_df.columns.str.lower()\n",
    "train_df.columns = train_df.columns.str.replace(' ','_')\n",
    "\n",
    "test_df.columns = test_df.columns.str.lower()\n",
    "test_df.columns = test_df.columns.str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d37d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert year to age train_df\n",
    "\n",
    "train_df['house_age'] = train_df['yr_sold'] - train_df['year_built']\n",
    "train_df['reno_age'] = train_df['yr_sold'] - train_df['year_remod/add']\n",
    "train_df['garage_age'] = train_df['yr_sold'] - train_df['garage_yr_blt']\n",
    "\n",
    "train_df.drop(columns=['year_built', 'year_remod/add', 'garage_yr_blt'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert year to age test_df\n",
    "\n",
    "test_df['house_age'] = test_df['yr_sold'] - test_df['year_built']\n",
    "test_df['reno_age'] = test_df['yr_sold'] - test_df['year_remod/add']\n",
    "test_df['garage_age'] = test_df['yr_sold'] - test_df['garage_yr_blt']\n",
    "\n",
    "test_df.drop(columns=['year_built', 'year_remod/add', 'garage_yr_blt'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d578fc",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd109de",
   "metadata": {},
   "source": [
    "###### Ordinal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab4589d",
   "metadata": {},
   "source": [
    "From data dictionary, we can see that some features are ordinal in nature. Convert these features to ordinal numbers to better represent the scale of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['exter_qual', 'exter_cond', 'bsmt_qual', 'bsmt_cond', 'kitchen_qual', 'garage_qual',\n",
    "           'garage_cond', 'heating_qc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to ordinal features\n",
    "\n",
    "# train_df\n",
    "\n",
    "for x in ordinal_features:\n",
    "    train_df[x].fillna(0, inplace=True)\n",
    "    train_df[x].replace('Po', 1, inplace=True)\n",
    "    train_df[x].replace('Fa', 2, inplace=True)\n",
    "    train_df[x].replace('TA', 3, inplace=True)\n",
    "    train_df[x].replace('Gd', 4, inplace=True)\n",
    "    train_df[x].replace('Ex', 5, inplace=True)\n",
    "    \n",
    "# test_df\n",
    "\n",
    "for x in ordinal_features:\n",
    "    test_df[x].fillna(0, inplace=True)\n",
    "    test_df[x].replace('Po', 1, inplace=True)\n",
    "    test_df[x].replace('Fa', 2, inplace=True)\n",
    "    test_df[x].replace('TA', 3, inplace=True)\n",
    "    test_df[x].replace('Gd', 4, inplace=True)\n",
    "    test_df[x].replace('Ex', 5, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8798220",
   "metadata": {},
   "source": [
    "###### Exploring Pearson's Correlation for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55014a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = train_df.corr()\n",
    "corr['saleprice'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c17df",
   "metadata": {},
   "source": [
    "There is a large number of features in the dataset, and some features may predict the target variable better than others. Dropping features that do not have a strong positive or negative Pearson's correlation with the target variable to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr['saleprice'].sort_values(ascending = False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da1626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0.2\n",
    "\n",
    "train_df.drop(columns = ['bsmt_unf_sf', 'bedroom_abvgr', 'screen_porch', '3ssn_porch',\n",
    "       'exter_cond', 'mo_sold', 'pool_area', 'bsmtfin_sf_2', 'misc_val',\n",
    "       'yr_sold', 'low_qual_fin_sf', 'bsmt_half_bath',  'ms_subclass',\n",
    "       'overall_cond', 'kitchen_abvgr', 'enclosed_porch'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ad061",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba830e2c",
   "metadata": {},
   "source": [
    "###### Checking for Multicollinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53ce47",
   "metadata": {},
   "source": [
    "Due to the large amount of features in the dataset, it is likely that a few features may be correlated to each other. Checking dataset for such features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd472af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(train_df.corr()[abs(train_df.corr()) >= 0.8])\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize= (12,8))\n",
    "sns.heatmap(train_df.corr()[abs(train_df.corr()) >= 0.8], annot= True, cmap = \"YlGnBu\", mask = mask)\n",
    "title = plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c338630",
   "metadata": {},
   "source": [
    "There are some features that show a strong correlation with each other.\n",
    "- 1st_flr_sf with total_bsmt_sf\n",
    "- gr_living_area with totrms_abvgrd\n",
    "- garage_cars with garage_area\n",
    "- garage_cond with garage_qual\n",
    "- garage_age with house_age<br>\n",
    "\n",
    "Dropping features with lower pearson's correlation with saleprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_bsmt_sf      0.628925\n",
    "# 1st_flr_sf         0.618486 drop\n",
    "\n",
    "# gr_liv_area        0.697038\n",
    "# totrms_abvgrd      0.504014 drop\n",
    "\n",
    "# garage_area        0.650270\n",
    "# garage_cars        0.648220 drop\n",
    "\n",
    "# garage_qual        0.285281\n",
    "# garage_cond        0.265021 drop\n",
    "\n",
    "# garage_age        -0.533962 drop\n",
    "# house_age         -0.571881\n",
    "\n",
    "train_df.drop(columns = ['1st_flr_sf', \n",
    "                         'totrms_abvgrd', \n",
    "                         'garage_cars', \n",
    "                         'garage_cond', \n",
    "                         'garage_age'], \n",
    "              inplace = True)\n",
    "\n",
    "test_df.drop(columns = ['1st_flr_sf', \n",
    "                         'totrms_abvgrd', \n",
    "                         'garage_cars', \n",
    "                         'garage_cond', \n",
    "                         'garage_age'], \n",
    "              inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4c6c7",
   "metadata": {},
   "source": [
    "###### Impute Numerical NaN values for Train dataset numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 101)\n",
    "train_nan = train_df.isnull().sum().sort_values(ascending = False)\n",
    "train_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415574f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_remove_col = []\n",
    "train_to_remove_val = []\n",
    "for col, val in train_nan.iteritems():\n",
    "    if val > 0:\n",
    "        train_to_remove_col.append(col)\n",
    "        train_to_remove_val.append(val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b819a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_to_remove_col\n",
    "width = train_to_remove_val\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "right_side = ax.spines[\"right\"]\n",
    "right_side.set_visible(False)\n",
    "top_side = ax.spines[\"top\"]\n",
    "top_side.set_visible(False)\n",
    "\n",
    "plt.barh(y, width,color='purple')\n",
    "plt.title(\"Train df numerical NaNs\", fontdict = {'fontsize' : 15})\n",
    "for index, value in enumerate(width):\n",
    "    plt.text(value + 100, index,\n",
    "             str(value))\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nan = test_df.isnull().sum().sort_values(ascending = False)\n",
    "test_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79394a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_remove_col = []\n",
    "test_to_remove_val = []\n",
    "for col, val in test_nan.iteritems():\n",
    "    if val > 0:\n",
    "        test_to_remove_col.append(col)\n",
    "        test_to_remove_val.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_to_remove_col\n",
    "width = test_to_remove_val\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "right_side = ax.spines[\"right\"]\n",
    "right_side.set_visible(False)\n",
    "top_side = ax.spines[\"top\"]\n",
    "top_side.set_visible(False)\n",
    "\n",
    "plt.barh(y, width,color='coral')\n",
    "plt.title(\"Test df numerical NaNs\", fontdict = {'fontsize' : 15})\n",
    "for index, value in enumerate(width):\n",
    "    plt.text(value + 50, index,\n",
    "             str(value))\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6175a07",
   "metadata": {},
   "source": [
    "Features pool_qc, misc_feature, alley, fence and fireplace_qu have more than 50% of missing data for both train and test dataset. Dropping these columns as they will not provide any useful information for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb9bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns with large missing data\n",
    "\n",
    "train_df.drop(columns = ['pool_qc', 'misc_feature', 'alley', 'fence', 'fireplace_qu'], inplace = True)\n",
    "test_df.drop(columns = ['pool_qc', 'misc_feature', 'alley', 'fence', 'fireplace_qu'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_num = train_df.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e9fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df_num].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1169d3",
   "metadata": {},
   "source": [
    "Lot Frontage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aeaae0",
   "metadata": {},
   "source": [
    "Lot Frontage NaN % is relatively high and it seems to be missing completely at random. <br>\n",
    "\n",
    "According to this [website](https://www.gimme-shelter.com/frontage-50043/), all houses have a lot frontage. It is the width of the lot.<br>\n",
    "\n",
    "Opt to impute with mean as both values for both data sets are not far off.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f04e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NaNs: ', train_df['lot_frontage'].isnull().sum())\n",
    "print('Total: ', train_df.shape[0])\n",
    "print('Percentage: ', (train_df['lot_frontage'].isnull().sum()/train_df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['lot_frontage'].mean())\n",
    "print(train_df['lot_frontage'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df['lot_frontage'].mean())\n",
    "print(test_df['lot_frontage'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the median and the mean for lot_frontage is about the same, fill lot_frontage nan with lot_frontage mean\n",
    "\n",
    "train_df['lot_frontage'].fillna(train_df['lot_frontage'].mean(),inplace=True)\n",
    "\n",
    "# imputing test_df does not affect kaggle score\n",
    "\n",
    "test_df['lot_frontage'].fillna(test_df['lot_frontage'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458d246",
   "metadata": {},
   "source": [
    "Replace remaining numerical feature NaNs with 0, as they are only a small percentage of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b692ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 0\n",
    "\n",
    "train_num_list = train_df.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "for feature in train_num_list:\n",
    "    train_df[feature].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_num_list].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f36999",
   "metadata": {},
   "source": [
    "##### Impute NaN values for train dataset categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da11862",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_list = train_df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "train_df[train_cat_list].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa091e4",
   "metadata": {},
   "source": [
    "For the catagorical features with NaN, they represent that the feature simply does not exist in the home. Replace all NaN with None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83cbae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train_cat_list:\n",
    "    train_df[feature].fillna('None', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb81b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_cat_list].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a906162",
   "metadata": {},
   "source": [
    "###### Plotting each numerical feature against target variable to check for any irregularities or outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57481656",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train_df.select_dtypes(exclude='object').columns.tolist():\n",
    "    plt.figure(figsize= ( 10, 5 ))\n",
    "    sns.scatterplot(data=train_df, x=feature, y='saleprice')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "\n",
    "train_df = train_df[(train_df['lot_frontage'] <=300)]\n",
    "train_df = train_df[(train_df['mas_vnr_area'] <=1400)]\n",
    "train_df = train_df[(train_df['bsmtfin_sf_1'] <=3000)]\n",
    "train_df = train_df[(train_df['total_bsmt_sf'] <=4000)]\n",
    "train_df = train_df[(train_df['gr_liv_area'] <=4000)]\n",
    "train_df = train_df[(train_df['wood_deck_sf'] <=1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b43bef",
   "metadata": {},
   "source": [
    "###### Plotting histograms to see the distribution of each numerical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd963233",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train_df.select_dtypes(exclude='object').columns.tolist():\n",
    "    plt.figure(figsize= ( 10, 5 ))\n",
    "    sns.histplot(data=train_df, x=feature, bins = 50, kde = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab996768",
   "metadata": {},
   "source": [
    "Histogram to see if the features are distributed normally. There are some features including our target variable that are right skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d749a07",
   "metadata": {},
   "source": [
    "###### Plotting box graphs to see if there is any relationships between each catagorical feature with our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train_df.select_dtypes(include='object').columns.tolist():\n",
    "    sns.boxplot(data=train_df, x=feature, y='saleprice')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8e6b3",
   "metadata": {},
   "source": [
    "Boxplots to see the relation of each catagorical feature with the saleprice. We can see that some features like ms_zoning, neighborhood, condition_1, condition_2, exterior_1st, exterior_2nd, garage_type and sale_type has some relation with saleprice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4c226",
   "metadata": {},
   "source": [
    "###### Matching features between Train and Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a43f5",
   "metadata": {},
   "source": [
    "Matching test dataframe colums with train dataframe columns. This will remove the dropped features from test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb50627",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list.remove('saleprice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c560e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[temp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04feeecc",
   "metadata": {},
   "source": [
    "##### Impute NaN values for test dataset numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95423204",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_num = test_df.select_dtypes(exclude='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df_num].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in test_df_num:\n",
    "    test_df[feature].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea7227",
   "metadata": {},
   "source": [
    "Replace missing value in mas_vnr_area with 0 as it is only 1 datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fbfd2c",
   "metadata": {},
   "source": [
    "##### Impute NaN values for test dataset numerical categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cf813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae80d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_cat = test_df.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bf7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df_cat].isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['electrical'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['electrical'].fillna('SBrkr', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41cfaad",
   "metadata": {},
   "source": [
    "Impute test_df electrical with mode 'SBrkr'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51085619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum().sort_values(ascending = False)\n",
    "test_df_cat = test_df.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in test_df_cat:\n",
    "    test_df[feature].fillna('None', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1650114",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c1475",
   "metadata": {},
   "source": [
    "Replace NaNs with 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a72179",
   "metadata": {},
   "source": [
    "### Get Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc55ce5",
   "metadata": {},
   "source": [
    "Dummify categorical features for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_cat = train_df.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7fa5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(data=train_df,columns=train_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29661e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_cat = test_df.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46521c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(data=test_df, columns=test_df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e36c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb3a9c",
   "metadata": {},
   "source": [
    "There are different columns in dummified train and test df. Checking which columns each df does not have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare list variable\n",
    "train_df_missing_col = []\n",
    "test_df_missing_col = []\n",
    "\n",
    "# append column missing in train_df\n",
    "\n",
    "for col in test_df.columns:\n",
    "    if col not in train_df.columns:\n",
    "        train_df_missing_col.append(col)\n",
    "        \n",
    "# append column missing in test_df\n",
    "\n",
    "for col in train_df.columns:\n",
    "    if col != 'saleprice':\n",
    "        if col not in test_df.columns:\n",
    "            test_df_missing_col.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f775e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_missing_col # columns in test not in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_missing_col # columns in train not in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60250ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[train_df_missing_col].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff046a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[test_df_missing_col].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc8384",
   "metadata": {},
   "source": [
    "Opting to remove missing columns from each dataset.<br>\n",
    "If columns were added, only a small percentage of meaningfull data will be added (ie 1/878 to 6/2043 $\\approx$ 0.1% to 0.3%) and a large percentage of noise will be included.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7884a438",
   "metadata": {},
   "source": [
    "Removing colums in train dataset that does not exist in test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns:\n",
    "    if col != 'saleprice':\n",
    "        if col not in test_df.columns:\n",
    "            print(col)\n",
    "            train_df.drop(columns=col, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27a0b5",
   "metadata": {},
   "source": [
    "Removing colums in test dataset that does not exist in train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_df.columns:\n",
    "    if col != 'saleprice':\n",
    "        if col not in train_df.columns:\n",
    "            print(col)\n",
    "            test_df.drop(columns=col, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38159bc",
   "metadata": {},
   "source": [
    "Only the saleprice column will be log transformed, as transforming the other features did not positively impact the model much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb9435",
   "metadata": {},
   "source": [
    "# Train and score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns = 'saleprice')\n",
    "y = train_df['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da529a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60281c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98013ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869386cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4edc36",
   "metadata": {},
   "source": [
    "### Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781a83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "\n",
    "y_baseline_pred = [np.mean(train_df['saleprice']) for i in range(len(y_test))]\n",
    "print(y_baseline_pred[:5])\n",
    "print(len(y_baseline_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline rmse\n",
    "\n",
    "baseline_rmse = mean_squared_error(y_test, y_baseline_pred, squared = False)\n",
    "baseline_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441dfa59",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fee2a5",
   "metadata": {},
   "source": [
    "Linear Regression model will make a the best fit line to predict the sale price. It takes into account all features, wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c05509",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train_sc, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c424b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_r2 = lr.score(X_train_sc, np.log(y_train))\n",
    "lr_test_r2 = lr.score(X_test_sc, np.log(y_test))\n",
    "lr_train_cv_r2 = cross_val_score(lr, X_train_sc, np.log(y_train), cv = 5).mean()\n",
    "lr_test_cv_r2 = cross_val_score(lr, X_test_sc,  np.log(y_test), cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by left way\n",
    "\n",
    "lr_y_pred = lr.predict(X_test_sc)\n",
    "lr_rmse = mean_squared_error(y_test, lr_y_pred, squared = False)\n",
    "lr_rmse_train = mean_squared_error(y_train, lr.predict(X_train_sc),squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727692d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # by right way\n",
    "\n",
    "# lr_y_pred = np.exp(lr.predict(X_test_sc))\n",
    "# lr_rmse = mean_squared_error(y_test, lr_y_pred, squared = False)\n",
    "# lr_rmse_train = mean_squared_error(y_train, np.exp(lr.predict(X_train_sc)),squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ededf",
   "metadata": {},
   "source": [
    "### Linear Regression with Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_alphas = np.logspace (-1, 10, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e49ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(r_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c64a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv.fit(X_train_sc, np.log(y_train))\n",
    "ridgecv_r2_train = (ridgecv.score(X_train_sc, np.log(y_train)))\n",
    "ridgecv_r2_test = (ridgecv.score(X_test_sc, np.log(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a669554",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_y_pred = np.exp(ridgecv.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_rmse = mean_squared_error(y_test,r_y_pred,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_rmse_train = mean_squared_error(y_train, np.exp(ridgecv.predict(X_train_sc)),squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2ea82",
   "metadata": {},
   "source": [
    "### Linear Regression with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = LassoCV(n_alphas = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548468e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv.fit(X_train_sc, np.log(y_train))\n",
    "lasso_train_r2 = lassocv.score(X_train_sc, np.log(y_train))\n",
    "lasso_test_r2 = lassocv.score(X_test_sc, np.log(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_y_pred = np.exp(lassocv.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e852751",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rmse = mean_squared_error(y_test,l_y_pred,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ee6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rmse_train = mean_squared_error(y_train, np.exp(lassocv.predict(X_train_sc)), squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a77b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_model():\n",
    "    t = PrettyTable(['Model', 'R2 Scores', 'RMSE'])\n",
    "\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "def model_scores():\n",
    "    t = PrettyTable(['Model', 'R2 Scores', 'RMSE'])\n",
    "    t.add_row(['Baseline', 'na', 'na'])\n",
    "    t.add_row(['Baseline', 'na', baseline_rmse])\n",
    "    t.add_row(['-------', '-------', '-------'])\n",
    "    t.add_row(['Linear Regression Train', lr_train_r2, lr_rmse_train])\n",
    "    t.add_row(['Linear Regression Train', lr_test_r2, lr_rmse])\n",
    "    t.add_row(['-------', '-------', '-------'])\n",
    "    t.add_row(['Ridge CV Train', ridgecv_r2_train, r_rmse_train])\n",
    "    t.add_row(['Ridge CV Test', ridgecv_r2_test, r_rmse])\n",
    "    t.add_row(['-------', '-------', '-------'])\n",
    "    t.add_row(['Lasso Train CV', lasso_train_r2, l_rmse_train])\n",
    "    t.add_row(['Lasso Test CV', lasso_test_r2, l_rmse])\n",
    "    t.add_row(['-------', '-------', '-------'])\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58983a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0403e0d",
   "metadata": {},
   "source": [
    "Looking at the R2 scores for all 3 models, Linear Regression did the worse with a very large difference between the train and test score. The model looked overfit. It could be due to the large number of features that were made in the process. We will use this as our baseline model. Comparing lasso and ridge R2 scores, both models have very high R2 scores, meaning that a high percentage of the variance of our target value can be explained by our features with our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18600a72",
   "metadata": {},
   "source": [
    "### Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs = pd.DataFrame(list(zip(np.exp(lassocv.coef_),X.columns)))\n",
    "lasso_coefs.rename(columns = { 0:\n",
    "                       'coef',\n",
    "                       1:\n",
    "                       'variable'}, inplace = True)\n",
    "lasso_coefs.sort_values(by='coef', ascending = False, inplace = True)\n",
    "lasso_coefs['coef'] = lasso_coefs['coef'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_coefs = pd.DataFrame(list(zip(np.exp(ridgecv.coef_),X.columns)))\n",
    "ridge_coefs.rename(columns = { 0:\n",
    "                       'coef',\n",
    "                       1:\n",
    "                       'variable'}, inplace = True)\n",
    "ridge_coefs.sort_values(by='coef', ascending = False, inplace = True)\n",
    "ridge_coefs['coef'] = ridge_coefs['coef'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ddf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_coefs = pd.DataFrame(list(zip(np.exp(lr.coef_),X.columns)))\n",
    "linear_coefs.rename(columns = { 0:\n",
    "                       'coef',\n",
    "                       1:\n",
    "                       'variable'}, inplace = True)\n",
    "linear_coefs.sort_values(by='coef', ascending = False, inplace = True)\n",
    "linear_coefs['coef'] = linear_coefs['coef'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fdc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recap corr from above\n",
    "\n",
    "corr['saleprice'].sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr['saleprice'].sort_values(ascending = False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084022dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_coefs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ebc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9566e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_coefs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b066cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_coefs.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f865bd7a",
   "metadata": {},
   "source": [
    "Coefficients mean that for every unit increase for the feature, our target will also increase. <br>\n",
    "<br>\n",
    "For Linear Regression with Ridge and Lasso, the top 5 positive coefficients are similar, mainly consisting of\n",
    "- gr_living_area ( above grade living area square feet )\n",
    "- overall_qual ( overall material and finish quality )\n",
    "- functional_typ ( home functionality rating: house with typical functionality )\n",
    "- functional_min1 ( home functionality rating: house with minor deductions 1)\n",
    "- functional_min2 ( home functionality rating : house with deductions 2)\n",
    "\n",
    "The top 5 negative coefficients are simiar,\n",
    "- reno_age ( number of years since last renovation )\n",
    "- house_age ( age of the house )\n",
    "- neighborhood_MeadowV ( Physical locations within Ames city limits: Meadow Village )\n",
    "- ms_zoning_c (  Identifies the general zoning classification of the sale: Commercial )\n",
    "- paved_drive_N ( Paved driveway: Dirt or gravel )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13510d75",
   "metadata": {},
   "source": [
    "### Distribution of Residuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdedb3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_residuals = y_test - l_y_pred\n",
    "lasso_joint = sns.jointplot(y=l_residuals,x=l_y_pred)\n",
    "lasso_joint.set_axis_labels('Lasso CV Predicted Values', 'Lasso CV Residuals', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_residuals = y_test - r_y_pred\n",
    "ridge_joint = sns.jointplot(y=r_residuals,x=r_y_pred)\n",
    "ridge_joint.set_axis_labels('Ridge CV Predicted Values', 'Ridge CV Residuals', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44cfdb",
   "metadata": {},
   "source": [
    "The distribution of residuals for both lasso and ridge seem to be normally distributed, satisfying the condition of normally distributed for linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930840d",
   "metadata": {},
   "source": [
    "### Kaggle Submission Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79975dd",
   "metadata": {},
   "source": [
    "###### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd383003",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sc = ss.fit_transform(X)\n",
    "test_sc = ss.transform(test_df)\n",
    "\n",
    "linear = LinearRegression()\n",
    "\n",
    "linear.fit(X_sc, np.log(y))\n",
    "\n",
    "chosen_y_pred = np.exp(linear.predict(test_sc))\n",
    "\n",
    "submission_ridge = pd.DataFrame()\n",
    "submission_ridge['Id'] = test_df['id']\n",
    "submission_ridge['SalePrice'] = chosen_y_pred\n",
    "submission_ridge.to_csv('./datasets/linear regression submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8ca7f",
   "metadata": {},
   "source": [
    "##### Linear Regression with Lasso Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7adda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_chosen = lassocv.alpha_\n",
    "\n",
    "X_sc = ss.fit_transform(X)\n",
    "test_sc = ss.transform(test_df)\n",
    "\n",
    "lasso = Lasso(alpha = lasso_chosen)\n",
    "\n",
    "lasso.fit(X_sc, np.log(y))\n",
    "\n",
    "print('R2 score:')\n",
    "print(lasso.score(X_sc, np.log(y)))\n",
    "\n",
    "chosen_l_y_pred = np.exp(lasso.predict(test_sc))\n",
    "\n",
    "submission_ridge = pd.DataFrame()\n",
    "submission_ridge['Id'] = test_df['id']\n",
    "submission_ridge['SalePrice'] = chosen_l_y_pred\n",
    "submission_ridge.to_csv('./datasets/lasso submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c9ab4",
   "metadata": {},
   "source": [
    "##### Linear Regression with Ridge Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae098bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_chosen = ridgecv.alpha_\n",
    "\n",
    "X_sc = ss.fit_transform(X)\n",
    "test_sc = ss.transform(test_df)\n",
    "\n",
    "ridge = Ridge(alpha = ridge_chosen)\n",
    "\n",
    "ridge.fit(X_sc, np.log(y))\n",
    "\n",
    "print('R2 score:')\n",
    "print(ridge.score(X_sc, np.log(y)))\n",
    "\n",
    "chosen_r_y_pred = np.exp(ridge.predict(test_sc))\n",
    "\n",
    "submission_ridge = pd.DataFrame()\n",
    "submission_ridge['Id'] = test_df['id']\n",
    "submission_ridge['SalePrice'] = chosen_r_y_pred\n",
    "submission_ridge.to_csv('./datasets/ridge submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedbbc7a",
   "metadata": {},
   "source": [
    "### Lasso Kaggle score: <br>\n",
    "Private: 19,874<br>\n",
    "Public: 21,076<br>\n",
    "It has a spread of 1202.<br><br>\n",
    "Ridge Kaggle score:<br>\n",
    "Private Score: 20,137<br>\n",
    "Public Score: 21,464<br>\n",
    "It has a spread of 1326."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1026c72",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9cb2a",
   "metadata": {},
   "source": [
    "###### Model Choice : Linear Regression with Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65261d47",
   "metadata": {},
   "source": [
    "Looking at the overall scoring for Linear Regression, it is not a good model for our situation as it is overfit.<br>\n",
    "<br>\n",
    "Using the train test scores for linear regression, we can see that for lasso and ridge, the training scores were a little lower. This is to be expected as we introduced some bias to get better accuracy, which can be seen in the test set R2 scores for lasso and ridge.<br>\n",
    "<br>\n",
    "Between Lasso and Ridge, both models gave good metrics, with a similar RMSE and coefficients. However, the best model for this case would be Linear Regression with Lasso, as it predicts the saleprice with the highest accuracy among the 3 models, and the lowst RMSE spread.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5876d4",
   "metadata": {},
   "source": [
    "###### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce48aa",
   "metadata": {},
   "source": [
    "Our model is able to predict sale price of a house, given it's features with an accuracy of +- $20,000 ( based on kaggle private score ). <br><br>\n",
    "Features that affect the sale price positively are:<br>\n",
    "- gr_living_area ( above grade living area square feet )\n",
    "- overall_qual ( overall material and finish quality )\n",
    "- functional_typ ( home functionality rating: house with typical functionality )\n",
    "- functional_min1 ( home functionality rating: house with minor deductions 1)\n",
    "- functional_min2 ( home functionality rating : house with deductions 2)<br><br>\n",
    "\n",
    "Features that affect the sale price negatively are:<br>\n",
    "- reno_age ( number of years since last renovation )\n",
    "- house_age ( age of the house )\n",
    "- neighborhood_MeadowV ( Physical locations within Ames city limits: Meadow Village )\n",
    "- ms_zoning_c (  Identifies the general zoning classification of the sale: Commercial )\n",
    "- paved_drive_N ( Paved driveway: Dirt or gravel )\n",
    "\n",
    "\n",
    "With this in mind, home buyers / sellers and real estate agents are able to get an outside view of the market rate of a house. They can have a rough feel of the price of the house by observing the features that positively and negatively affect the price.<br>\n",
    "They can also use the model to get a clearer picture of theh saleprice. In this way, they will not overpay / under price / estimate inaccurately the value of a house<br>\n",
    "Buyers and real estate agents are able to pick out under priced house, and sellers know when they are offered a good price."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
